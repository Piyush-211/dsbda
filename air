
import pandas as pd
import numpy as np
df = pd.read_csv('airquality_data.csv', encoding='cp1252')
df.head()
df.info()
df.columns

#Data Cleaning
# Change data type from float64 to float32 for Space Complexity
df['so2'] = df['so2'].astype('float32')
df['no2'] = df['no2'].astype('float32')
df['rspm'] = df['rspm'].astype('float32')
df['spm'] = df['spm'].astype('float32')
df['date'] = df['date'].astype('string')
df.info()
df=df.drop_duplicates()
df.isna().sum()
percent_missing = df.isnull().sum() * 100 / len(df)
percent_missing.sort_values(ascending=False)
df=df.drop(['stn_code', 'agency','sampling_date','location_monitoring_station','pm2_5'], axis = 1)
df.head()
df.columns
col_var = ['state', 'location', 'type','date']
col_num = ['so2','no2','rspm','spm']
for col in df.columns:
    if df[col].dtype == 'object' or df[col].dtype == 'string':
        df[col] = df[col].fillna(df[col].mode()[0])
    else:
        df[col] = df[col].fillna(df[col].mean())
df.isna().sum()
df
df.isna().sum()
#Data integration
subSet1 = df[['state', 'type']]
subSet2 = df[['state','location']]
subSet1.head()
subSet2.head()
concatenated_df = pd.concat([subSet1, subSet2], axis=1)
concatenated_df

#Error Correcting
def remove_outliers(column):
    Q1 = column.quantile(0.25)
    Q3 = column.quantile(0.75)
    IQR = Q3 - Q1
    threshold = 1.5 * IQR
    outlier_mask = (column < Q1 - threshold) | (column > Q3 + threshold)
    return column[~outlier_mask]
df.columns
# Remove outliers for each column using a loop
col_name = ['so2', 'no2', 'rspm', 'spm']
for col in col_name:
    df[col] = remove_outliers(df[col])
import seaborn as sns
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 6))  # Adjust the figure size if needed

for col in col_name:
    sns.boxplot(data=df[col])
    plt.title(col)
    plt.show()

#Data Transform
from sklearn.preprocessing import LabelEncoder

col_label= ['state','location','type']
# Initialize LabelEncoder

encoder = LabelEncoder()
# Iterate over columns
for col in df.columns:
        # Fit and transform the column
        df[col] = encoder.fit_transform(df[col])
df



from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

# Features and Target
X = df.drop('spm', axis=1)  # Features
y = df['spm']               # Target

# Split Data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Model
model = RandomForestRegressor()
model.fit(X_train, y_train)

# Prediction
y_pred = model.predict(X_test)

# Evaluation
mse = mean_squared_error(y_test, y_pred)
print(f'Mean Squared Error: {mse}')



from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# 1. Separate features (X) and target (y)
X = df.drop('spm', axis=1)  # all columns except 'spm'
y = df['spm']               # target column

# 2. Split into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)

# 3. Create and train the model
model = LinearRegression()
model.fit(X_train, y_train)

# 4. Predict on the test set
y_pred = model.predict(X_test)

# 5. Evaluate the model
mse = mean_squared_error(y_test, y_pred)
print("Mean Squared Error:", mse)

# 6. Optional: Show actual vs predicted
import pandas as pd
results = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})
print(results.head())


